models:
  mlp_ensemble:
    ensemble_size: 5
    batch_size: 64
    validation_split: 0.2
    learning_rate: 0.00025
    learning_rate_decay: 0.98
    training_steps: 5000
    mlp_params:
      n_layers: 4
      units: 128
      activation: tf.nn.relu
      dropout_rate: 0.0
