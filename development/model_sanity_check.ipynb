{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Spread Toy Example\n",
    "## Initilization Anchored NN Ensemble Sanity Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I want to demonstrate that my tensorflow implementation of the ensemble neural network is actually working and useful. In the spirit of times, I will try to learn the _hypothetical_ spreading of the COVID-19 disease in the _hypothetical_ island of Wakanda through the period of one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simba.models.mlp_ensemble import MlpEnsemble\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate some data using the [SIR model](https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html) of covid19: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covid_19_infection_rate_data():\n",
    "    # https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html\n",
    "    # https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/\n",
    "    population = 15000\n",
    "    days = 365\n",
    "    i_0, r_0 = 2, 0\n",
    "    s_0 = population - i_0 - r_0\n",
    "    beta, gamma = 0.3, 0.02\n",
    "    t = np.linspace(0, days, days)\n",
    "\n",
    "    def deriv(y, t, population, beta, gamma):\n",
    "        S, I, R = y\n",
    "        dSdt = -beta * S * I / population\n",
    "        dIdt = beta * S * I / population - gamma * I\n",
    "        dRdt = gamma * I\n",
    "        return dSdt, dIdt, dRdt\n",
    "    y_0 = s_0, i_0, r_0\n",
    "    ret = odeint(deriv, y_0, t, args=(population, beta, gamma))\n",
    "    _, infected_people, _ = ret.transpose()\n",
    "    return t, infected_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have only have access to noisy measurements of how many people were sick on a certain day: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, infected_people = generate_covid_19_infection_rate_data()\n",
    "n_samples = 25\n",
    "noise = 0.01\n",
    "time_augmented = np.array([])\n",
    "infected_people_samples = np.array([])\n",
    "for day, sick_people_that_day in zip(time, infected_people):\n",
    "    time_augmented = np.append(time_augmented, np.full(n_samples, day))\n",
    "    infected_people_samples = np.append(infected_people_samples, np.random.normal(\n",
    "    sick_people_that_day, noise * sick_people_that_day, n_samples))\n",
    "time_val = np.linspace(0, 365, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    mlp_dict = dict(\n",
    "        n_layers=5,\n",
    "        units=64,\n",
    "        activation=tf.nn.relu,\n",
    "        dropout_rate=0.0\n",
    "    )\n",
    "    ensemble = MlpEnsemble(\n",
    "        inputs_dim=1,\n",
    "        outputs_dim=1,\n",
    "        ensemble_size=1,\n",
    "        n_epochs=20,\n",
    "        batch_size=10,\n",
    "        validation_split=0.0,\n",
    "        learning_rate=0.1,\n",
    "        mlp_params=mlp_dict\n",
    "    )\n",
    "    ensemble.build()\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ensemble\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "ensemble/id_0 (GaussianDistM (None, 63)                18048     \n",
      "=================================================================\n",
      "Total params: 18,048\n",
      "Trainable params: 17,408\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Train on 9125 samples\n",
      "Epoch 1/20\n",
      "9125/9125 [==============================] - 4s 450us/sample - loss: 766117.4313\n",
      "Epoch 2/20\n",
      "9125/9125 [==============================] - 1s 152us/sample - loss: 166764.8971\n",
      "Epoch 3/20\n",
      "9125/9125 [==============================] - 1s 157us/sample - loss: 114895.7948\n",
      "Epoch 4/20\n",
      "9125/9125 [==============================] - 2s 167us/sample - loss: 84682.2748\n",
      "Epoch 5/20\n",
      "9125/9125 [==============================] - 2s 214us/sample - loss: 71375.1214\n",
      "Epoch 6/20\n",
      "9125/9125 [==============================] - 2s 184us/sample - loss: 60119.5863\n",
      "Epoch 7/20\n",
      "9125/9125 [==============================] - 2s 220us/sample - loss: 55514.4205\n",
      "Epoch 8/20\n",
      "9125/9125 [==============================] - 2s 233us/sample - loss: 48129.7126\n",
      "Epoch 9/20\n",
      "9125/9125 [==============================] - 2s 213us/sample - loss: 41706.0762\n",
      "Epoch 10/20\n",
      "9125/9125 [==============================] - 2s 237us/sample - loss: 45362.3403\n",
      "Epoch 11/20\n",
      "9125/9125 [==============================] - 2s 181us/sample - loss: 43937.1149\n",
      "Epoch 12/20\n",
      "9125/9125 [==============================] - 2s 211us/sample - loss: 39759.8117\n",
      "Epoch 13/20\n",
      "9125/9125 [==============================] - 2s 209us/sample - loss: 36503.9536\n",
      "Epoch 14/20\n",
      "9125/9125 [==============================] - 2s 214us/sample - loss: 33454.5578\n",
      "Epoch 15/20\n",
      "9125/9125 [==============================] - 2s 203us/sample - loss: 30972.3269\n",
      "Epoch 16/20\n",
      "9125/9125 [==============================] - 2s 217us/sample - loss: 27846.1140\n",
      "Epoch 17/20\n",
      "9125/9125 [==============================] - 2s 208us/sample - loss: 24988.9013\n",
      "Epoch 18/20\n",
      "9125/9125 [==============================] - 2s 203us/sample - loss: 22834.2932\n",
      "Epoch 19/20\n",
      "9125/9125 [==============================] - 2s 197us/sample - loss: 22567.2039\n",
      "Epoch 20/20\n",
      "9125/9125 [==============================] - 2s 212us/sample - loss: 21058.1746\n",
      "WARNING:tensorflow:Layer ensemble/id_0 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer ensemble/id_0 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_particles = 20\n",
    "x_test = np.broadcast_to(time_val, (n_particles, time_val.shape[0]))\n",
    "x_test = np.reshape(x_test, (n_particles * time_val.shape[0]))\n",
    "data_mean = time_augmented.mean()\n",
    "data_std = time_augmented.std()\n",
    "x = np.squeeze((time_augmented - data_mean) / (data_std + 1e-8))\n",
    "x_test = (x_test - data_mean) / (data_std + 1e-8)\n",
    "model = make_model()\n",
    "model.fit(x[:, np.newaxis], infected_people_samples[:, np.newaxis])\n",
    "mus, sigmas, preds = np.squeeze(model.predict(x_test[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total uncertainty (epistemic and aleatoric) using monte-carlo estimation using data sampled from _ensemble_size_ and _n\\_particles_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more details on decomposition of uncertainties: http://proceedings.mlr.press/v80/depeweg18a/depeweg18a.pdf \n",
    "preds = np.reshape(preds, \n",
    "                  (model.ensemble_size, n_particles, time_val.shape[0]))\n",
    "aleatoric_monte_carlo_uncertainty = np.mean(np.std(preds, axis=1) ** 2, axis=0)\n",
    "epistemic_monte_carlo_uncertainty = np.std(np.mean(preds, axis=1), axis=0) ** 2\n",
    "total_monte_carlo_uncertainty = aleatoric_monte_carlo_uncertainty + epistemic_monte_carlo_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = fig.subplots()\n",
    "ax.set_ylim([-100, 12.5e3])\n",
    "ax.scatter(time_augmented, infected_people_samples, color='#FF9671', alpha=0.09,\n",
    "           s=20, label='Infected today people a day')\n",
    "ax.plot(time_val, np.mean(preds, axis=(0, 1)), '-', color='#845EC2', linewidth=1.5, \n",
    "       label='Mean over all particles and MLPs', alpha=0.8)\n",
    "ax.fill_between(time_val, np.mean(preds, axis=(0, 1)) - np.sqrt(total_monte_carlo_uncertainty),\n",
    "                np.mean(preds, axis=(0, 1)) + np.sqrt(total_monte_carlo_uncertainty),\n",
    "                color='#FF6F91', alpha=0.5, label='Total monte-carlo standard deviation')\n",
    "ax.legend(loc='upper right', fontsize='medium')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Infectious people\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.reshape(mus, \n",
    "                  (model.ensemble_size, n_particles, time_val.shape[0]))\n",
    "sigmas = np.reshape(sigmas, \n",
    "                  (model.ensemble_size, n_particles, time_val.shape[0]))\n",
    "aleatoric_explicit_uncertainty = np.mean(sigmas ** 2, axis=(0, 1))\n",
    "fig = plt.figure(figsize=(10, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(time_val, aleatoric_monte_carlo_uncertainty, label='Monte-carlo estimated aleatoric uncertainty')\n",
    "ax1.plot(time_val, aleatoric_explicit_uncertainty, label='Explicit aleatoric uncertainty')\n",
    "ax1.plot(time, (infected_people * noise) ** 2, label='Ground truth')\n",
    "ax1.legend(loc='upper right', fontsize='medium')\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(time_val, epistemic_monte_carlo_uncertainty, label='Monte-carlo epistemic uncertainty')\n",
    "ax2.legend(loc='upper right', fontsize='medium')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
