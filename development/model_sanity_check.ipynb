{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Spread Toy Example\n",
    "## Initilization Anchored NN Ensemble Sanity Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I want to demonstrate that my tensorflow implementation of the ensemble neural network is actually working and useful. In the spirit of times, I will try to learn the _hypothetical_ spreading of the COVID-19 disease in the _hypothetical_ island of Wakanda through the period of one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simba.models.mlp_ensemble import MlpEnsemble\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate some data using the [SIR model](https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html) of covid19: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covid_19_infection_rate_data():\n",
    "    # https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html\n",
    "    # https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/\n",
    "    population = 15000\n",
    "    days = 365\n",
    "    i_0, r_0 = 2, 0\n",
    "    s_0 = population - i_0 - r_0\n",
    "    beta, gamma = 0.3, 0.02\n",
    "    t = np.linspace(0, days, days)\n",
    "\n",
    "    def deriv(y, t, population, beta, gamma):\n",
    "        S, I, R = y\n",
    "        dSdt = -beta * S * I / population\n",
    "        dIdt = beta * S * I / population - gamma * I\n",
    "        dRdt = gamma * I\n",
    "        return dSdt, dIdt, dRdt\n",
    "    y_0 = s_0, i_0, r_0\n",
    "    ret = odeint(deriv, y_0, t, args=(population, beta, gamma))\n",
    "    _, infected_people, _ = ret.transpose()\n",
    "    return t, infected_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have only have access to noisy measurements of how many people were sick on a certain day: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, infected_people = generate_covid_19_infection_rate_data()\n",
    "n_samples = 25\n",
    "noise = 0.01\n",
    "time_augmented = np.array([])\n",
    "infected_people_samples = np.array([])\n",
    "for day, sick_people_that_day in zip(time, infected_people):\n",
    "    time_augmented = np.append(time_augmented, np.full(n_samples, day))\n",
    "    infected_people_samples = np.append(infected_people_samples, np.random.normal(\n",
    "    sick_people_that_day, noise * sick_people_that_day, n_samples))\n",
    "time_val = np.linspace(0, 365, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    mlp_dict = dict(\n",
    "        n_layers=5,\n",
    "        units=64,\n",
    "        activation=tf.nn.relu,\n",
    "        dropout_rate=0.0\n",
    "    )\n",
    "    ensemble = MlpEnsemble(\n",
    "        inputs_dim=1,\n",
    "        outputs_dim=1,\n",
    "        ensemble_size=5,\n",
    "        n_epochs=30,\n",
    "        batch_size=64,\n",
    "        validation_split=0.0,\n",
    "        learning_rate=0.1,\n",
    "        mlp_params=mlp_dict\n",
    "    )\n",
    "    ensemble.build()\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ensemble\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble/id_0 (GaussianDistMlp) (None, 63)           16768       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble/id_1 (GaussianDistMlp) (None, 63)           16768       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble/id_2 (GaussianDistMlp) (None, 63)           16768       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble/id_3 (GaussianDistMlp) (None, 63)           16768       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble/id_4 (GaussianDistMlp) (None, 63)           16768       input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 83,840\n",
      "Trainable params: 83,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 9125 samples\n",
      "Epoch 1/30\n",
      "9125/9125 [==============================] - 3s 322us/sample - loss: 5436530.8066 - ensemble/id_0_loss: 728501.6875 - ensemble/id_1_loss: 706842.9375 - ensemble/id_2_loss: 1197956.1250 - ensemble/id_3_loss: 1941014.6250 - ensemble/id_4_loss: 849681.3125\n",
      "Epoch 2/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 743410.9713 - ensemble/id_0_loss: 26737.6582 - ensemble/id_1_loss: 20875.3418 - ensemble/id_2_loss: 141706.6562 - ensemble/id_3_loss: 439774.1875 - ensemble/id_4_loss: 113640.1328\n",
      "Epoch 3/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 611324.6298 - ensemble/id_0_loss: 764.8878 - ensemble/id_1_loss: 23622.3262 - ensemble/id_2_loss: 65286.8594 - ensemble/id_3_loss: 439737.7812 - ensemble/id_4_loss: 81229.4375\n",
      "Epoch 4/30\n",
      "9125/9125 [==============================] - 1s 89us/sample - loss: 515675.4481 - ensemble/id_0_loss: 8818.9336 - ensemble/id_1_loss: 3011.0710 - ensemble/id_2_loss: 53161.0430 - ensemble/id_3_loss: 440161.9062 - ensemble/id_4_loss: 10466.2656\n",
      "Epoch 5/30\n",
      "9125/9125 [==============================] - 1s 86us/sample - loss: 503311.1630 - ensemble/id_0_loss: 17227.1270 - ensemble/id_1_loss: 15189.3516 - ensemble/id_2_loss: 1391.5984 - ensemble/id_3_loss: 440602.6875 - ensemble/id_4_loss: 29374.3633\n",
      "Epoch 6/30\n",
      "9125/9125 [==============================] - 1s 89us/sample - loss: 457533.0288 - ensemble/id_0_loss: 1856.4305 - ensemble/id_1_loss: 10630.7217 - ensemble/id_2_loss: 991.2194 - ensemble/id_3_loss: 440131.3750 - ensemble/id_4_loss: 3892.4431\n",
      "Epoch 7/30\n",
      "9125/9125 [==============================] - 1s 88us/sample - loss: 456406.8080 - ensemble/id_0_loss: 6212.0718 - ensemble/id_1_loss: 7394.7168 - ensemble/id_2_loss: 1228.1176 - ensemble/id_3_loss: 440370.7188 - ensemble/id_4_loss: 1424.0020\n",
      "Epoch 8/30\n",
      "9125/9125 [==============================] - 1s 93us/sample - loss: 503416.5442 - ensemble/id_0_loss: 24000.5488 - ensemble/id_1_loss: 16104.3740 - ensemble/id_2_loss: 20519.5410 - ensemble/id_3_loss: 439510.0312 - ensemble/id_4_loss: 2780.2761\n",
      "Epoch 9/30\n",
      "9125/9125 [==============================] - 1s 91us/sample - loss: 467505.1937 - ensemble/id_0_loss: 3603.6824 - ensemble/id_1_loss: 242.4167 - ensemble/id_2_loss: 19764.6074 - ensemble/id_3_loss: 440342.4688 - ensemble/id_4_loss: 3699.7849\n",
      "Epoch 10/30\n",
      "9125/9125 [==============================] - 1s 89us/sample - loss: 463764.4021 - ensemble/id_0_loss: 1651.8380 - ensemble/id_1_loss: 212.9757 - ensemble/id_2_loss: 14053.3291 - ensemble/id_3_loss: 440047.8750 - ensemble/id_4_loss: 7705.6895\n",
      "Epoch 11/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 465265.8853 - ensemble/id_0_loss: 150.0612 - ensemble/id_1_loss: 205.8319 - ensemble/id_2_loss: 8880.5488 - ensemble/id_3_loss: 440381.6250 - ensemble/id_4_loss: 16004.2988\n",
      "Epoch 12/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 688747.3191 - ensemble/id_0_loss: 383.3391 - ensemble/id_1_loss: 198.1176 - ensemble/id_2_loss: 241071.9375 - ensemble/id_3_loss: 439525.0312 - ensemble/id_4_loss: 6257.6763\n",
      "Epoch 13/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 452737.0632 - ensemble/id_0_loss: 989.2314 - ensemble/id_1_loss: 134.5780 - ensemble/id_2_loss: 1142.2528 - ensemble/id_3_loss: 439380.9375 - ensemble/id_4_loss: 10328.3145\n",
      "Epoch 14/30\n",
      "9125/9125 [==============================] - 1s 88us/sample - loss: 455058.7532 - ensemble/id_0_loss: 432.9677 - ensemble/id_1_loss: 123.9521 - ensemble/id_2_loss: 78.0649 - ensemble/id_3_loss: 439914.4688 - ensemble/id_4_loss: 14294.1709\n",
      "Epoch 15/30\n",
      "9125/9125 [==============================] - 1s 92us/sample - loss: 445420.0280 - ensemble/id_0_loss: 345.7168 - ensemble/id_1_loss: 164.3222 - ensemble/id_2_loss: 9.7458 - ensemble/id_3_loss: 440039.5938 - ensemble/id_4_loss: 4756.4990\n",
      "Epoch 16/30\n",
      "9125/9125 [==============================] - 1s 88us/sample - loss: 449461.2154 - ensemble/id_0_loss: 7493.7510 - ensemble/id_1_loss: 139.9647 - ensemble/id_2_loss: 9.8560 - ensemble/id_3_loss: 440268.6250 - ensemble/id_4_loss: 1693.9259\n",
      "Epoch 17/30\n",
      "9125/9125 [==============================] - 1s 91us/sample - loss: 447252.2229 - ensemble/id_0_loss: 2804.7478 - ensemble/id_1_loss: 163.7690 - ensemble/id_2_loss: 9.7777 - ensemble/id_3_loss: 440365.8125 - ensemble/id_4_loss: 4146.8350\n",
      "Epoch 18/30\n",
      "9125/9125 [==============================] - 1s 89us/sample - loss: 444279.2932 - ensemble/id_0_loss: 1778.8997 - ensemble/id_1_loss: 157.6960 - ensemble/id_2_loss: 9.8738 - ensemble/id_3_loss: 440728.1562 - ensemble/id_4_loss: 2204.9385\n",
      "Epoch 19/30\n",
      "9125/9125 [==============================] - 1s 92us/sample - loss: 492270.5238 - ensemble/id_0_loss: 326.3605 - ensemble/id_1_loss: 152.3763 - ensemble/id_2_loss: 9.9767 - ensemble/id_3_loss: 440171.5938 - ensemble/id_4_loss: 51516.0508\n",
      "Epoch 20/30\n",
      "9125/9125 [==============================] - 1s 91us/sample - loss: 449188.8711 - ensemble/id_0_loss: 1080.0651 - ensemble/id_1_loss: 225.0034 - ensemble/id_2_loss: 10.0566 - ensemble/id_3_loss: 439574.2812 - ensemble/id_4_loss: 7753.6562\n",
      "Epoch 21/30\n",
      "9125/9125 [==============================] - 1s 91us/sample - loss: 451222.4325 - ensemble/id_0_loss: 5615.9258 - ensemble/id_1_loss: 683.9849 - ensemble/id_2_loss: 9.7159 - ensemble/id_3_loss: 439508.9375 - ensemble/id_4_loss: 4765.7437\n",
      "Epoch 22/30\n",
      "9125/9125 [==============================] - 1s 87us/sample - loss: 447592.8818 - ensemble/id_0_loss: 2102.5215 - ensemble/id_1_loss: 498.2678 - ensemble/id_2_loss: 10.4587 - ensemble/id_3_loss: 441485.5312 - ensemble/id_4_loss: 3284.5364\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9125/9125 [==============================] - 1s 90us/sample - loss: 530556.0384 - ensemble/id_0_loss: 2042.9897 - ensemble/id_1_loss: 272.6963 - ensemble/id_2_loss: 10.1715 - ensemble/id_3_loss: 439456.3438 - ensemble/id_4_loss: 87839.2188\n",
      "Epoch 24/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 456625.2674 - ensemble/id_0_loss: 427.8676 - ensemble/id_1_loss: 149.0378 - ensemble/id_2_loss: 10.1635 - ensemble/id_3_loss: 440089.5938 - ensemble/id_4_loss: 15874.4775\n",
      "Epoch 25/30\n",
      "9125/9125 [==============================] - 1s 86us/sample - loss: 469115.3951 - ensemble/id_0_loss: 1202.2601 - ensemble/id_1_loss: 186.1196 - ensemble/id_2_loss: 10.1383 - ensemble/id_3_loss: 439507.6875 - ensemble/id_4_loss: 27524.9824\n",
      "Epoch 26/30\n",
      "9125/9125 [==============================] - 1s 87us/sample - loss: 445223.2439 - ensemble/id_0_loss: 1116.8333 - ensemble/id_1_loss: 214.8105 - ensemble/id_2_loss: 10.1037 - ensemble/id_3_loss: 439812.5938 - ensemble/id_4_loss: 3761.8281\n",
      "Epoch 27/30\n",
      "9125/9125 [==============================] - 1s 85us/sample - loss: 459392.8798 - ensemble/id_0_loss: 1649.1143 - ensemble/id_1_loss: 216.9614 - ensemble/id_2_loss: 10.0542 - ensemble/id_3_loss: 440369.3125 - ensemble/id_4_loss: 17329.1680\n",
      "Epoch 28/30\n",
      "9125/9125 [==============================] - 1s 89us/sample - loss: 450021.8076 - ensemble/id_0_loss: 1403.3043 - ensemble/id_1_loss: 767.1367 - ensemble/id_2_loss: 10.0053 - ensemble/id_3_loss: 439406.7500 - ensemble/id_4_loss: 7719.3354\n",
      "Epoch 29/30\n",
      "9125/9125 [==============================] - 1s 87us/sample - loss: 456080.6268 - ensemble/id_0_loss: 9805.9160 - ensemble/id_1_loss: 1851.3907 - ensemble/id_2_loss: 9.9683 - ensemble/id_3_loss: 439885.7812 - ensemble/id_4_loss: 4234.1841\n",
      "Epoch 30/30\n",
      "9125/9125 [==============================] - 1s 90us/sample - loss: 450207.2829 - ensemble/id_0_loss: 5435.0918 - ensemble/id_1_loss: 3520.5188 - ensemble/id_2_loss: 9.9374 - ensemble/id_3_loss: 440534.0938 - ensemble/id_4_loss: 1085.2998\n",
      "WARNING:tensorflow:Layer ensemble/id_0 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Could not compute output tfp.distributions.Normal(\"ensemble_id_1_sequential_1_distribution_lambda_1_Normal\", batch_shape=[?, 63], event_shape=[], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c6087b4e7075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfected_people_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# mus, sigmas, preds = np.squeeze(model.predict(x_test[:, np.newaxis]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not compute output '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0moutput_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Could not compute output tfp.distributions.Normal(\"ensemble_id_1_sequential_1_distribution_lambda_1_Normal\", batch_shape=[?, 63], event_shape=[], dtype=float32)"
     ]
    }
   ],
   "source": [
    "n_particles = 20\n",
    "x_test = np.broadcast_to(time_val, (n_particles, time_val.shape[0]))\n",
    "x_test = np.reshape(x_test, (n_particles * time_val.shape[0]))\n",
    "data_mean = time_augmented.mean()\n",
    "data_std = time_augmented.std()\n",
    "x = np.squeeze((time_augmented - data_mean) / (data_std + 1e-8))\n",
    "x_test = (x_test - data_mean) / (data_std + 1e-8)\n",
    "model = make_model()\n",
    "import time\n",
    "t0 = time.time()\n",
    "model.fit(x[:, np.newaxis], infected_people_samples[:, np.newaxis])\n",
    "model.ensemble(x_test[:, np.newaxis])\n",
    "# mus, sigmas, preds = np.squeeze(model.predict(x_test[:, np.newaxis]))\n",
    "t1 = time.time()\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lala = [x_test[:, np.newaxis] for _ in range(5)]\n",
    "model.ensemble(lala)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total uncertainty (epistemic and aleatoric) using monte-carlo estimation using data sampled from _ensemble_size_ and _n\\_particles_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more details on decomposition of uncertainties: http://proceedings.mlr.press/v80/depeweg18a/depeweg18a.pdf \n",
    "preds = np.reshape(preds, \n",
    "                  (model.ensemble_size, n_particles, time_val.shape[0]))\n",
    "aleatoric_monte_carlo_uncertainty = np.mean(np.std(preds, axis=1) ** 2, axis=0)\n",
    "epistemic_monte_carlo_uncertainty = np.std(np.mean(preds, axis=1), axis=0) ** 2\n",
    "total_monte_carlo_uncertainty = aleatoric_monte_carlo_uncertainty + epistemic_monte_carlo_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = fig.subplots()\n",
    "ax.set_ylim([-100, 12.5e3])\n",
    "ax.scatter(time_augmented, infected_people_samples, color='#FF9671', alpha=0.09,\n",
    "           s=20, label='Infected today people a day')\n",
    "ax.plot(time_val, np.mean(preds, axis=(0, 1)), '-', color='#845EC2', linewidth=1.5, \n",
    "       label='Mean over all particles and MLPs', alpha=0.8)\n",
    "ax.fill_between(time_val, np.mean(preds, axis=(0, 1)) - np.sqrt(total_monte_carlo_uncertainty),\n",
    "                np.mean(preds, axis=(0, 1)) + np.sqrt(total_monte_carlo_uncertainty),\n",
    "                color='#FF6F91', alpha=0.5, label='Total monte-carlo standard deviation')\n",
    "ax.legend(loc='upper right', fontsize='medium')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Infectious people\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.reshape(mus, \n",
    "                  (model.ensemble_size, n_particles, time_val.shape[0]))\n",
    "sigmas = np.reshape(sigmas, \n",
    "                  (model.ensemble_size, n_particles, time_val.shape[0]))\n",
    "aleatoric_explicit_uncertainty = np.mean(sigmas ** 2, axis=(0, 1))\n",
    "fig = plt.figure(figsize=(10, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(time_val, aleatoric_monte_carlo_uncertainty, label='Monte-carlo estimated aleatoric uncertainty')\n",
    "ax1.plot(time_val, aleatoric_explicit_uncertainty, label='Explicit aleatoric uncertainty')\n",
    "ax1.plot(time, (infected_people * noise) ** 2, label='Ground truth')\n",
    "ax1.legend(loc='upper right', fontsize='medium')\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(time_val, epistemic_monte_carlo_uncertainty, label='Monte-carlo epistemic uncertainty')\n",
    "ax2.legend(loc='upper right', fontsize='medium')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
